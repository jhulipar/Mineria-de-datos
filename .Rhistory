# define funciones de tidymodels por defecto
tidymodels_prefer()
train_data<-read.csv("ALUMNOS-trainData.csv")%>%
unique()
eval_data<-read.csv("ALUMNOS-evalData.csv")%>%
unique()
#Limpiar data
sapply(train_data, function(x) sum(is.na(x))) #Comprueba cantidad de NA
train_data =train_data[!is.na(train_data$departure_time),] #Borrar NA
train_data =train_data[!duplicated(train_data$id),] #Borrar id duplicado
train_data$class<-with(train_data,ifelse(noshow>=4,1,0)) #Asignar a class 0 y 1 dependiendo de NoShow
train_data$noshow <- NULL
View(eval_data)
View(train_data)
eval_data<-merge(eval_data, train_data, by = c("id", "id"))
View(eval_data)
eval_data<-merge(eval_data, train_data, by = c("id", "id"),all = TRUE)
eval_data<-read.csv("ALUMNOS-evalData.csv")%>%
unique()
eval_data<-merge(eval_data, train_data, by = c("id", "id"),all = TRUE)
eval_data<-read.csv("ALUMNOS-evalData.csv")%>%
unique()
set.seed(44)
eval_data<-merge(train_data,eval_data,  by = c("id", "id"),all = TRUE)
eval_data<-read.csv("ALUMNOS-evalData.csv")%>%
unique()
eval_data<-merge(train_data,eval_data,  by = "id")
eval_data<-read.csv("ALUMNOS-evalData.csv")%>%
unique()
eval_data<-merge(eval_data,train_data,  by = "id")
eval_data<-read.csv("ALUMNOS-evalData.csv")%>%
unique()
eval_data1<-merge(eval_data,train_data,  by = "id")
View(train_data)
View(eval_data)
View(train_data)
View(eval_data1)
eval_data<-read.csv("ALUMNOS-evalData.csv")%>%
unique()
eval_data1<-merge(eval_data,train_data,  by = id)
# cargo librerias
pacman::p_load(tidymodels, kknn,dplyr)
eval_data1<-inner_join(eval_data,train_data,  by = 'id')
eval_data1<-merge(eval_data,train_data,  by = "id",all = FALSE)
eval_data1<-merge(eval_data,train_data,  by = "id",all.x = TRUE, all.y= FALSE)
View(eval_data1)
eval_data1<-sqldf("SELECT eval_data.*,train_data FROM train_data,eval_data WHERE train_data.id=eval_data.id")
# cargo librerias
pacman::p_load(tidymodels, kknn,sqldf)
# cargo librerias
pacman::p_load(tidymodels, kknn,sqldf)
eval_data1<-merge(train_data,eval_data)
eval_data1<-merge(train_data,eval_data,all = FALSE)
train_data<-read.csv("ALUMNOS-trainData.csv") #%>% unique()
eval_data<-read.csv("ALUMNOS-evalData.csv")%>%
unique()
eval_data1<-merge(train_data,eval_data,all = FALSE)
?initial_split
pacman::p_load(tidymodels, kknn)
set.seed(44)
# define funciones de tidymodels por defecto
tidymodels_prefer()
train_data<-read.csv("ALUMNOS-trainData.csv")%>%
unique() %>%
sample_n(10000)
#Limpiar data
sapply(train_data, function(x) sum(is.na(x))) #Comprueba cantidad de NA
train_data =train_data[!is.na(train_data$departure_time),] #Borrar NA
train_data =train_data[!duplicated(train_data$id),] #Borrar id duplicado
train_data$class<-with(train_data,ifelse(noshow>=4,1,0)) #Asignar a class 0 y 1 dependiendo de NoShow
train_data$noshow <- NULL #Borrar NoShow para entrenar correctamente
data_split_strat <- initial_split(train_data, prop = 3/4, strata = arr_delay)
train_data <- training(data_split_strat)
test_data  <- testing(data_split_strat)
train_data %>%
count(arr_delay) %>%
mutate(prop = n/sum(n))
#Seleccionar las variables
train_data<-select(train_data,date,departure_time,destination)
# generamos la receta
# cargo librerias
pacman::p_load(tidymodels, kknn,tidymodels, discrim,kernlab,MLmetrics)
pacman::p_load(tidymodels, kknn,tidymodels, discrim,kernlab,MLmetrics)
set.seed(44)
# define funciones de tidymodels por defecto
tidymodels_prefer()
train_data<-read.csv("ALUMNOS-trainData.csv")%>%
unique() %>%
sample_n(10000)
#Limpiar data
sapply(train_data, function(x) sum(is.na(x))) #Comprueba cantidad de NA
train_data =train_data[!is.na(train_data$departure_time),] #Borrar NA
train_data =train_data[!duplicated(train_data$id),] #Borrar id duplicado
train_data$class<-with(train_data,ifelse(noshow>=4,1,0)) #Asignar a class 0 y 1 dependiendo de NoShow
train_data$noshow <- NULL #Borrar NoShow para entrenar correctamente
data_split_strat <- initial_split(train_data, prop = 3/4, strata = arr_delay)
train_data <- training(data_split_strat)
test_data  <- testing(data_split_strat)
train_data %>%
count(arr_delay) %>%
mutate(prop = n/sum(n))
#Seleccionar las variables
train_data<-select(train_data,date,departure_time,destination)
# generamos la receta
set.seed(44)
# define funciones de tidymodels por defecto
tidymodels_prefer()
train_data<-read.csv("ALUMNOS-trainData.csv")%>%
unique() %>%
sample_n(10000)
#Limpiar data
sapply(train_data, function(x) sum(is.na(x))) #Comprueba cantidad de NA
train_data =train_data[!is.na(train_data$departure_time),] #Borrar NA
train_data =train_data[!duplicated(train_data$id),] #Borrar id duplicado
train_data$class<-with(train_data,ifelse(noshow>=4,1,0)) #Asignar a class 0 y 1 dependiendo de NoShow
train_data$noshow <- NULL #Borrar NoShow para entrenar correctamente
data_split_strat <- initial_split(train_data, prop = 3/4, strata = class)
train_data <- training(data_split_strat)
test_data  <- testing(data_split_strat)
train_data %>%
count(arr_delay) %>%
mutate(prop = n/sum(n))
#Seleccionar las variables
train_data<-select(train_data,date,departure_time,destination)
# generamos la receta
# cargo librerias
pacman::p_load(tidymodels, kknn,tidymodels, discrim,kernlab,MLmetrics)
set.seed(44)
# define funciones de tidymodels por defecto
tidymodels_prefer()
train_data<-read.csv("ALUMNOS-trainData.csv")%>%
unique() %>%
sample_n(10000)
#Limpiar data
sapply(train_data, function(x) sum(is.na(x))) #Comprueba cantidad de NA
train_data =train_data[!is.na(train_data$departure_time),] #Borrar NA
train_data =train_data[!duplicated(train_data$id),] #Borrar id duplicado
train_data$class<-with(train_data,ifelse(noshow>=4,1,0)) #Asignar a class 0 y 1 dependiendo de NoShow
train_data$noshow <- NULL #Borrar NoShow para entrenar correctamente
data_split_strat <- initial_split(train_data, prop = 3/4, strata = class)
train_data <- training(data_split_strat)
test_data  <- testing(data_split_strat)
train_data %>%
count(arr_delay) %>%
mutate(prop = n/sum(n))
train_data %>%
count(class) %>%
mutate(prop = n/sum(n))
#Seleccionar las variables
train_data<-select(train_data,date,departure_time,destination)
# generamos la receta
receta <-
recipe(Exited ~ ., data = train_data)
# generamos la receta
receta <-
recipe(class ~ ., data = train_data)
#Seleccionar las variables
train_data<-select(train_data,date,departure_time,destination)
# generamos la receta
receta <-
recipe(class ~ ., data = train_data)
View(train_data)
#definimos el modelo con 1 grado polinomial
modelo <- svm_poly(degree = 1) %>%
set_engine("kernlab") %>%
set_mode("classification") %>%
translate()
modelo
# generamos la receta
receta <-
recipe(class ~ ., data = train_data)
gc()
pacman::p_load(tidyverse, tidymodels, discrim,kernlab,MLmetrics)
set.seed(42)
# leemos data de churn (rotacion)
data <- read_csv("data/Churn_Modelling.csv") %>%
mutate(is_female = ifelse(Gender == "Female",1,0),
Exited = as.factor(Exited)) %>%
select(-RowNumber, -Surname, -Geography, -Gender, -CustomerId) %>%
relocate(Exited)
# echamos un vistazo
data %>% glimpse()
# dividimos data entrenamiento prueba
data_split <- initial_split(data, prop = 3/4)
train_data <- training(data_split)
test_data  <- testing(data_split)
nrow(test_data)
train_data %>% nrow()
setwd("~/GitHub/Mineria-de-datos")
pacman::p_load(tidyverse, tidymodels, discrim,kernlab,MLmetrics)
set.seed(42)
# leemos data de churn (rotacion)
data <- read_csv("data/Churn_Modelling.csv") %>%
mutate(is_female = ifelse(Gender == "Female",1,0),
Exited = as.factor(Exited)) %>%
select(-RowNumber, -Surname, -Geography, -Gender, -CustomerId) %>%
relocate(Exited)
# echamos un vistazo
data %>% glimpse()
# dividimos data entrenamiento prueba
data_split <- initial_split(data, prop = 3/4)
train_data <- training(data_split)
test_data  <- testing(data_split)
nrow(test_data)
train_data %>% nrow()
View(train_data)
View(train_data)
#Seleccionar las variables
train_data<-select(train_data,date,departure_time,destination)%>%
relocate(class)
pacman::p_load(tidymodels, kknn,tidymodels, discrim,kernlab,MLmetrics)
set.seed(44)
# define funciones de tidymodels por defecto
tidymodels_prefer()
train_data<-read.csv("~/GitHub/Mineria-de-datos/proyectos/Proyecto 2/ALUMNOS-trainData.csv")%>%
unique() %>%
sample_n(10000)
#Limpiar data
sapply(train_data, function(x) sum(is.na(x))) #Comprueba cantidad de NA
train_data =train_data[!is.na(train_data$departure_time),] #Borrar NA
train_data =train_data[!duplicated(train_data$id),] #Borrar id duplicado
train_data$class<-with(train_data,ifelse(noshow>=4,1,0)) #Asignar a class 0 y 1 dependiendo de NoShow
train_data$noshow <- NULL #Borrar NoShow para entrenar correctamente
data_split_strat <- initial_split(train_data, prop = 3/4, strata = class)
train_data <- training(data_split_strat)
test_data  <- testing(data_split_strat)
train_data %>%
count(class) %>%
mutate(prop = n/sum(n))
#Seleccionar las variables
train_data<-select(train_data,date,departure_time,destination)%>%
relocate(class)
# generamos la receta
#Seleccionar las variables
train_data<-select(train_data,class,date,departure_time,destination)
# generamos la receta
receta <-
recipe(class ~ ., data = train_data)
receta
#definimos el modelo con 1 grado polinomial
modelo <- svm_poly(degree = 1) %>%
set_engine("kernlab") %>%
set_mode("classification") %>%
translate()
modelo
# definimos funcion fitea igual que otras oportunidades
fitea <- function(mod){
modelo_fit <-
workflow() %>%
add_model(mod) %>%
add_recipe(receta) %>%
fit(data = train_data)
model_pred <-
predict(modelo_fit, test_data, type = "prob") %>%
bind_cols(test_data)
return(model_pred %>%
roc_auc(truth = Exited, .pred_0))
}
# ajustamos el modelo
fitea(modelo)
?set_mode
View(test_data)
pacman::p_load(tidymodels, kknn,tidymodels, discrim,kernlab,MLmetrics)
set.seed(44)
# define funciones de tidymodels por defecto
tidymodels_prefer()
train_data<-read.csv("~/GitHub/Mineria-de-datos/proyectos/Proyecto 2/ALUMNOS-trainData.csv")%>%
unique() %>%
sample_n(10000)
#Limpiar data
sapply(train_data, function(x) sum(is.na(x))) #Comprueba cantidad de NA
train_data =train_data[!is.na(train_data$departure_time),] #Borrar NA
train_data =train_data[!duplicated(train_data$id),] #Borrar id duplicado
train_data$class<-with(train_data,ifelse(noshow>=4,1,0)) #Asignar a class 0 y 1 dependiendo de NoShow
train_data$noshow <- NULL #Borrar NoShow para entrenar correctamente
data_split_strat <- initial_split(train_data, prop = 3/4, strata = class)
train_data <- training(data_split_strat)
test_data  <- testing(data_split_strat)
train_data %>%
count(class) %>%
mutate(prop = n/sum(n))
#Seleccionar las variables
train_data<-select(train_data,class,date,departure_time,distance)
# generamos la receta
receta <-
recipe(class ~ ., data = train_data)
receta
#definimos el modelo con 1 grado polinomial
modelo <- svm_poly(degree = 1) %>%
set_engine("kernlab") %>%
set_mode("classification") %>%
translate()
modelo
# definimos funcion fitea igual que otras oportunidades
fitea <- function(mod){
modelo_fit <-
workflow() %>%
add_model(mod) %>%
add_recipe(receta) %>%
fit(data = train_data)
model_pred <-
predict(modelo_fit, test_data, type = "prob") %>%
bind_cols(test_data)
return(model_pred %>%
roc_auc(truth = Exited, .pred_0))
}
# ajustamos el modelo
fitea(modelo)
# generamos otra funcion para fitear en diferentes grados polinomiales
fitea_polySVM <- function(grado){
mod <- svm_poly(degree = grado) %>%
set_engine("kernlab") %>%
set_mode("classification") %>%
translate()
modelo_fit <-
workflow() %>%
add_model(mod) %>%
add_recipe(receta) %>%
fit(data = train_data)
model_pred <-
predict(modelo_fit, test_data, type = "prob") %>%
bind_cols(test_data)
return(model_pred %>%
metrics(class, .pred_class))
}
mod <- svm_poly(degree = 1) %>%
set_engine("kernlab") %>%
set_mode("classification") %>%
translate()
modelo_fit <-
workflow() %>%
add_model(mod) %>%
add_recipe(receta) %>%
fit(data = train_data)
model_pred <-
predict(modelo_fit, test_data, type = "prob") %>%
bind_cols(test_data)
mod <- svm_poly(degree = 1) %>%
set_engine("kernlab") %>%
set_mode("classification") %>%
translate()
modelo_fit <-
workflow() %>%
add_model(mod) %>%
add_recipe(receta) %>%
fit(data = train_data)
pacman::p_load(tidymodels, kknn,tidymodels, discrim,kernlab,MLmetrics)
set.seed(44)
# define funciones de tidymodels por defecto
tidymodels_prefer()
train_data<-read.csv("~/GitHub/Mineria-de-datos/proyectos/Proyecto 2/ALUMNOS-trainData.csv")%>%
unique() %>%
sample_n(10000)
#Limpiar data
sapply(train_data, function(x) sum(is.na(x))) #Comprueba cantidad de NA
train_data =train_data[!is.na(train_data$departure_time),] #Borrar NA
train_data =train_data[!duplicated(train_data$id),] #Borrar id duplicado
train_data$class<-with(train_data,ifelse(noshow>=4,1,0)) #Asignar a class 0 y 1 dependiendo de NoShow
train_data$noshow <- NULL #Borrar NoShow para entrenar correctamente
data_split_strat <- initial_split(train_data, prop = 3/4, strata = class)
train_data <- training(data_split_strat)
test_data  <- testing(data_split_strat)
train_data %>%
count(class) %>%
mutate(prop = n/sum(n))
train_data<-mutate(class=factor(class),date=lubridate::as_date(time_hour))%>%
mutate_if(is.character, as.factor)
train_data<-mutate(class=factor(class),date=lubridate::as_date(time_hour))%>%
mutate_if(is.character, as.factor)
train_data<-mutate(train_data,class=factor(class),date=lubridate::as_date(time_hour))%>%
mutate_if(is.character, as.factor)
train_data<-mutate(train_data,class=factor(class))%>%
mutate_if(is.character, as.factor)
#Seleccionar las variables
train_data<-select(train_data,class,date,departure_time,distance)
View(test_data)
#Seleccionar las variables
train_data<-select(train_data,class,date,departure_time,destination)
pacman::p_load(tidymodels, kknn,tidymodels, discrim,kernlab,MLmetrics)
set.seed(44)
# define funciones de tidymodels por defecto
tidymodels_prefer()
train_data<-read.csv("~/GitHub/Mineria-de-datos/proyectos/Proyecto 2/ALUMNOS-trainData.csv")%>%
unique() %>%
sample_n(10000)
#Limpiar data
sapply(train_data, function(x) sum(is.na(x))) #Comprueba cantidad de NA
train_data =train_data[!is.na(train_data$departure_time),] #Borrar NA
train_data =train_data[!duplicated(train_data$id),] #Borrar id duplicado
train_data$class<-with(train_data,ifelse(noshow>=4,1,0)) #Asignar a class 0 y 1 dependiendo de NoShow
train_data$noshow <- NULL #Borrar NoShow para entrenar correctamente
data_split_strat <- initial_split(train_data, prop = 3/4, strata = class)
train_data <- training(data_split_strat)
test_data  <- testing(data_split_strat)
train_data %>%
count(class) %>%
mutate(prop = n/sum(n))
train_data<-mutate(train_data,class=factor(class))%>%
mutate_if(is.character, as.factor)
#Seleccionar las variables
train_data<-select(train_data,class,date,departure_time,destination)
receta <-
recipe(class ~ ., data = train_data)
receta
#definimos el modelo con 1 grado polinomial
modelo <- svm_poly(degree = 1) %>%
set_engine("kernlab") %>%
set_mode("classification") %>%
translate()
modelo
# definimos funcion fitea igual que otras oportunidades
fitea <- function(mod){
modelo_fit <-
workflow() %>%
add_model(mod) %>%
add_recipe(receta) %>%
fit(data = train_data)
model_pred <-
predict(modelo_fit, test_data, type = "prob") %>%
bind_cols(test_data)
return(model_pred %>%
roc_auc(truth = Exited, .pred_0))
}
# ajustamos el modelo
fitea(modelo)
# generamos otra funcion para fitear en diferentes grados polinomiales
fitea_polySVM <- function(grado){
mod <- svm_poly(degree = grado) %>%
set_engine("kernlab") %>%
set_mode("classification") %>%
translate()
modelo_fit <-
workflow() %>%
add_model(mod) %>%
add_recipe(receta) %>%
fit(data = train_data)
model_pred <-
predict(modelo_fit, test_data, type = "prob") %>%
bind_cols(test_data)
return(model_pred %>%
metrics(class, .pred_class))
}
fitea_polySVM(1)
pacman::p_load(tidymodels, tidyverse, nycflights13)
set.seed(42)
# cargar y limpiar datos ----
flight_data <-
flights %>%
mutate(
# discretiza arr_delay y lo hace factor
arr_delay = ifelse(arr_delay >= 30, "late", "on_time"),
arr_delay = factor(arr_delay),
# obtengo solo la fecha a partir de fecha con hora
date = lubridate::as_date(time_hour)
) %>%
# combino con data de clima
inner_join(weather, by = c("origin", "time_hour")) %>%
# especifico las columnas de interes
select(dep_time, flight, origin, dest, air_time, distance,
carrier, date, arr_delay, time_hour) %>%
# excluyo datos faltates
na.omit() %>%
# transformo characteres en factores
mutate_if(is.character, as.factor)  %>%
# tomo una muestra de tamaño 10.000 para poder ejecutar los modelos
sample_n(10000)
pacman::p_load(tidymodels, tidyverse, nycflights13)
set.seed(42)
# cargar y limpiar datos ----
flight_data <-
flights %>%
mutate(
# discretiza arr_delay y lo hace factor
arr_delay = ifelse(arr_delay >= 30, "late", "on_time"),
arr_delay = factor(arr_delay),
# obtengo solo la fecha a partir de fecha con hora
date = lubridate::as_date(time_hour)
) %>%
# combino con data de clima
inner_join(weather, by = c("origin", "time_hour")) %>%
# especifico las columnas de interes
select(dep_time, flight, origin, dest, air_time, distance,
carrier, date, arr_delay, time_hour) %>%
# excluyo datos faltates
na.omit() %>%
# transformo characteres en factores
mutate_if(is.character, as.factor)  %>%
# tomo una muestra de tamaño 10.000 para poder ejecutar los modelos
sample_n(10000)
pacman::p_load(tidymodels, tidyverse, nycflights13)
pacman::p_load(tidymodels, kknn,tidymodels, discrim,kernlab,MLmetrics)
set.seed(44)
# define funciones de tidymodels por defecto
tidymodels_prefer()
train_data<-read.csv("~/GitHub/Mineria-de-datos/proyectos/Proyecto 2/ALUMNOS-trainData.csv")%>%
unique() %>%
sample_n(10000)
#Limpiar data
sapply(train_data, function(x) sum(is.na(x))) #Comprueba cantidad de NA
train_data =train_data[!is.na(train_data$departure_time),] #Borrar NA
train_data =train_data[!duplicated(train_data$id),] #Borrar id duplicado
train_data$class<-with(train_data,ifelse(noshow>=4,1,0)) #Asignar a class 0 y 1 dependiendo de NoShow
train_data$noshow <- NULL #Borrar NoShow para entrenar correctamente
data_split_strat <- initial_split(train_data, prop = 3/4, strata = class)
train_data <- training(data_split_strat)
test_data  <- testing(data_split_strat)
train_data %>%
count(class) %>%
mutate(prop = n/sum(n))
train_data<-mutate(train_data,class=factor(class),date = lubridate::as_date(date))%>%
mutate_if(is.character, as.factor)
View(train_data)
