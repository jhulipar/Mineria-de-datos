if(is.null(h) & model == "hier") {h <- data %>% cov() %>% diag() %>% sum() %>% sqrt()}
if(is.null(k) & (model %in% c("kmeans", "cmeans", "gmm"))) {k <- floor(sqrt(nrow(data)))}
if(model %in% models){
if(model == "kmeans"){
object   <- kmeans(data, k)
clusters <- object$cluster
} else if(model == "cmeans"){
object   <- e1071::cmeans(data, k, m = fuzz)
clusters <- object$cluster
} else if(model == "gmm"){
object   <- mclust::Mclust(data, G=k, modelNames = cov)
clusters <- object$classification
} else if(model == "dbscan"){
object   <- dbscan::dbscan(data, eps=eps, minPts  = minpts)
clusters <- object$cluster
} else if(model == "hier"){
object   <- hclust(dist(data), method = linkage)
clusters <- cutree(object, h = h)
}
if(return.model){
return(object)
} else {
return(clusters)
}
} else {
print("modelo no soportado")
}
}
siluetas <- NULL
for(m in models){
if(m == "hier"){
for(lnk in linkage){
for(dis in dists){
c <- clusteriza(data_tsne, model = m, linkage = lnk, h = dis)
siluetas <- rbind(siluetas, c(mean(silhouette(c, d)[,3]), paste0(m, "-linkage:",lnk,"-h:",dis)))
}
}
}
if(m == "kmeans"){
for(ks in nks){
c <- clusteriza(data_tsne, model = m, k = ks)
siluetas <- rbind(siluetas, c(mean(silhouette(c, d)[,3]), paste0(m, "-k:",ks)))
}
}
if(m == "cmeans"){
for(ks in nks){
for(fz in 2:10){
c <- clusteriza(data_tsne, model = m, k = ks, fuzz = fz)
siluetas <- rbind(siluetas, c(mean(silhouette(c, d)[,3]), paste0(m, "-k:",ks,"-fuzz:",fz)))
}
}
}
if(m == "gmm"){
for(ks in nks){
for(cv in cov){
c <- clusteriza(data_tsne, model = m, k = ks, cov = cv)
siluetas <- rbind(siluetas, c(mean(silhouette(c, d)[,3]), paste0(m, "-k:",ks,"-cov:",cv)))
}
}
}
if(m == "dbscan"){
for(ep in dists){
for(mp in 5*(1:9)){
c <- clusteriza(data_tsne, model = m, eps = ep, minpts = mp)
siluetas <- rbind(siluetas, c(mean(silhouette(c, d)[,3]), paste0(m, "-eps:",eps,"-minpts:",mp)))
}
}
}
}
m
h
lnk
dis
c <- clusteriza(data_tsne, model = m, linkage = lnk, h = dis)
silhouette(c, d)
c
? cutree
clusteriza <- function(data, model, k = NULL, linkage = "complete",
h = NULL, cov = "EII", minpts = 5,
eps = NULL, fuzz = 2, return.model = FALSE){
if(is.null(eps) & model == "dbscan") {eps <- data %>% cov() %>% diag() %>% sum() %>% sqrt()}
if(is.null(k) & (model %in% c("kmeans", "cmeans", "gmm"))) {k <- floor(sqrt(nrow(data)))}
if(model %in% models){
if(model == "kmeans"){
object   <- kmeans(data, k)
clusters <- object$cluster
} else if(model == "cmeans"){
object   <- e1071::cmeans(data, k, m = fuzz)
clusters <- object$cluster
} else if(model == "gmm"){
object   <- mclust::Mclust(data, G=k, modelNames = cov)
clusters <- object$classification
} else if(model == "dbscan"){
object   <- dbscan::dbscan(data, eps=eps, minPts  = minpts)
clusters <- object$cluster
} else if(model == "hier"){
object   <- hclust(dist(data), method = linkage)
clusters <- cutree(object, k = k)
}
if(return.model){
return(object)
} else {
return(clusters)
}
} else {
print("modelo no soportado")
}
}
for(m in models){
if(m == "hier"){
for(lnk in linkage){
for(ks in nks){
c <- clusteriza(data_tsne, model = m, linkage = lnk, k = ks)
siluetas <- rbind(siluetas, c(mean(silhouette(c, d)[,3]), paste0(m, "-linkage:",lnk,"-h:",dis)))
}
}
}
if(m == "kmeans"){
for(ks in nks){
c <- clusteriza(data_tsne, model = m, k = ks)
siluetas <- rbind(siluetas, c(mean(silhouette(c, d)[,3]), paste0(m, "-k:",ks)))
}
}
if(m == "cmeans"){
for(ks in nks){
for(fz in 2:10){
c <- clusteriza(data_tsne, model = m, k = ks, fuzz = fz)
siluetas <- rbind(siluetas, c(mean(silhouette(c, d)[,3]), paste0(m, "-k:",ks,"-fuzz:",fz)))
}
}
}
if(m == "gmm"){
for(ks in nks){
for(cv in cov){
c <- clusteriza(data_tsne, model = m, k = ks, cov = cv)
siluetas <- rbind(siluetas, c(mean(silhouette(c, d)[,3]), paste0(m, "-k:",ks,"-cov:",cv)))
}
}
}
if(m == "dbscan"){
for(ep in dists){
for(mp in 5*(1:9)){
c <- clusteriza(data_tsne, model = m, eps = ep, minpts = mp)
siluetas <- rbind(siluetas, c(mean(silhouette(c, d)[,3]), paste0(m, "-eps:",eps,"-minpts:",mp)))
}
}
}
}
# creamos vector vacio para almacenar siluetas
siluetas <- numeric(20)
# creamos vector vacio para almacenar siluetas
siluetas <- numeric(20)
for (k in 2:20){
# ejecutamos kmedias con k centroides
modelo <- kmeans(data_tsne, centers = k)
# cramos objeto con la silueta
temp <- silhouette(modelo$cluster, dist(data_tsne))
# almacenamos la silueta promedio del modelo
siluetas[k] <- mean(temp[,3])
}
tempDF <- data.frame(CS=siluetas, K=c(1:20))
# visualizamos
ggplot(tempDF, aes(x=K, y=CS)) +
geom_line() +
scale_x_continuous(breaks=c(1:20)) +
geom_vline(xintercept = which(tempDF$CS == max(tempDF$CS)), col = "red")
source("R/clusteriza.R")
# cargo librerias
pacman::p_load(tidyverse, Rtsne, mclust, e1071, cluster, flexclust, factoextra)
set.seed(42)
# cargo la data y aplico los mismos tratamientos que en el caso de DBScan
data_tsne  <- read.csv("data/video_games_sales.csv") %>%
mutate(User_Score = as.numeric(User_Score)) %>%
filter(!(is.na(Critic_Score) | is.na(User_Score))) %>%
select(Critic_Score, User_Score, User_Count, Global_Sales) %>%
unique() %>%
Rtsne() %>%
.$Y %>%
as.data.frame()
# exploramos graficamente la data
ggplot(data_tsne) +
geom_point(aes(V1,V2))
# antes de clusterizar, evaluamos el grado de clusterizacion natural de los datos de acuerdo
# al estadistico de hopkins, que esta implementado en la libreria factoextra.
#Calcula el hopkins statistic
(res <- get_clust_tendency(data_tsne, n = 30, graph = FALSE))
## Evaluacion de clusters
# ejecutamos un modelo para probar su clusterizacion
modelo_kmeans <- kmeans(data_tsne, 13)
# almacenamos los clusters en un vector que contiene el numero de cada cluster y el indice
clusters <- modelo_kmeans$cluster
# calculamos las distancias de los datos
distancias <- dist(data_tsne) %>% as.matrix()
View(distancias)
# generamos indices con la ubicacion de los clusters ordenados
clusters_i <-  sort(clusters, index.return=TRUE)
clusters_i$ix
#reordeno filas y columnas en base al cluster obtenido
distancias <- distancias[clusters_i$ix, clusters_i$ix]
rownames(distancias) <- c(1:nrow(data_tsne))
colnames(distancias) <- c(1:nrow(data_tsne))
# pero la matriz de distancias es muy grande para graficar
print(object.size(distancias), units = "Mb")
# la extraemos 1 de cada 10 filas y columnas
n <- 10
ids <- (1:floor(nrow(distancias)/n))*n
dist_reducida <- distancias[ids,ids]
# bajo considerablemente el tamaÃ±o
print(object.size(dist_reducida), units = "Mb")
# generamos la imagen de la matriz para la inspececion visual
image(dist_reducida)
# creo matriz llega de ceros
matriz_ideal <- matrix(0, nrow = nrow(data_tsne), ncol = nrow(data_tsne))
# creo matriz llega de ceros
matriz_ideal <- matrix(0, nrow = nrow(data_tsne), ncol = nrow(data_tsne))
# para cada cluster reemplazo con 1 en aquellas entidades que pertenezcan a el
for(k in unique(clusters_i$x)){
matriz_ideal[which(clusters_i$x==k), which(clusters_i$x==k)]  <- 1
}
# construyo matriz de disimilitud en base a la distancia ordenada
tempDist2 <- 1/(1+distancias)
? cor
# Calcula correlacion entre matriz de disimilitud y matriz optima
cor <- cor(matriz_ideal[upper.tri(matriz_ideal)],tempDist2[upper.tri(tempDist2)])
print(cor)
# creamos vector vacio para medir la cohesion en cada cluster
withinCluster <- numeric(length(unique(clusters)))
withinCluster
# creamos vector vacio para medir la cohesion en cada cluster
withinCluster <- numeric(length(unique(clusters)))
# para cada cluster
for (i in 1:length(withinCluster)){
# extraigo los puntos pertenecientes al cluster i
tempData <- data_tsne[which(clusters == i),]
# calculo la suma de distancias al cuadrado entre cada punto y el centroide
withinCluster[i] <- sum(dist2(tempData,colMeans(tempData))^2)
}
# calculo la suma total de cohesion para todos los clusters
cohesion <- sum(withinCluster)
#es equivalente a model$tot.withinss en k-means
print(c(cohesion, modelo_kmeans$tot.withinss))
centroide_total <- colMeans(data_tsne)
centroide_total
# creamos vector vacio para almacenar separacion en cada cluster
separation <-  numeric(length(unique(clusters)))
# para cada cluster
for (i in 1:length(separation)){
# extraigo los puntos pertenecientes al cluster i
tempData <- data_tsne[which(clusters==i),]
# calculo la separacion como la distancia promedio entre cada punto de un cluster y el resto
separation[i] <- nrow(tempData)*sum((meanData-colMeans(tempData))^2)
}
# creamos vector vacio para almacenar separacion en cada cluster
separation <-  numeric(length(unique(clusters)))
# para cada cluster
for (i in 1:length(separation)){
# extraigo los puntos pertenecientes al cluster i
tempData <- data_tsne[which(clusters==i),]
# calculo la separacion como la distancia promedio entre cada punto de un cluster y el resto
separation[i] <- nrow(tempData)*sum((separation-colMeans(tempData))^2)
}
(sum(separation))
centroide_total <- colMeans(data_tsne)
# creamos vector vacio para almacenar separacion en cada cluster
separation <-  numeric(length(unique(clusters)))
# para cada cluster
for (i in 1:length(separation)){
# extraigo los puntos pertenecientes al cluster i
tempData <- data_tsne[which(clusters==i),]
# calculo la separacion como la distancia promedio entre cada punto de un cluster y el resto
separation[i] <- nrow(tempData)*sum((centroide_total-colMeans(tempData))^2)
}
(sum(separation))
? silhouette
clusters
# el coeficiente recibe las etiquetas de cluster y la matriz de distancias de la data original
coefSil <- silhouette(clusters, dist(data_tsne))
summary(coefSil)
coefSil[,3]
#visualizamos el codigo de silueta de cada cluster
fviz_silhouette(coefSil) + coord_flip()
# el coeficiente recibe las etiquetas de cluster y la matriz de distancias de la data original
coefSil <- silhouette(clusters, dist(data_tsne))
#visualizamos el codigo de silueta de cada cluster
fviz_silhouette(coefSil) + coord_flip()
# creamos vector vacio para almacenar siluetas
siluetas <- numeric(20)
# creamos vector vacio para almacenar siluetas
siluetas <- numeric(20)
for (k in 2:20){
# ejecutamos kmedias con k centroides
modelo <- kmeans(data_tsne, centers = k)
# cramos objeto con la silueta
temp <- silhouette(modelo$cluster, dist(data_tsne))
# almacenamos la silueta promedio del modelo
siluetas[k] <- mean(temp[,3])
}
tempDF <- data.frame(CS=siluetas, K=c(1:20))
# visualizamos
ggplot(tempDF, aes(x=K, y=CS)) +
geom_line() +
scale_x_continuous(breaks=c(1:20)) +
geom_vline(xintercept = which(tempDF$CS == max(tempDF$CS)), col = "red")
source("R/clusteriza.R")
tuesdata <- tidytuesdayR::tt_load('2020-09-22')
library(munro)
pacman::p_load(tidymodels)
library(rlang)
library(tidymodels)
tidymodels_prefer()
pacman::p_load(tidymodels)
tidymodels_prefer()
data(Chicago)
n <- nrow(Chicago)
Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)
Chicago_train <- Chicago[1:(n - 7), ]
Chicago_test <- Chicago[(n - 6):n, ]
knn_reg_spec <-
nearest_neighbor(neighbors = 5, weight_func = "triangular") %>%
# This model can be used for classification or regression, so set mode
set_mode("regression") %>%
set_engine("kknn")
knn_reg_spec
knn_reg_fit <- knn_reg_spec %>% fit(ridership ~ ., data = Chicago_train)
knn_reg_fit
install.packages("kknn")
knn_reg_fit <- knn_reg_spec %>% fit(ridership ~ ., data = Chicago_train)
knn_reg_fit
predict(knn_reg_fit, Chicago_test)
data(two_class_dat)
data_train <- two_class_dat[-(1:10), ]
data_test  <- two_class_dat[  1:10 , ]
knn_cls_spec <-
nearest_neighbor(neighbors = 11, weight_func = "triangular") %>%
# This model can be used for classification or regression, so set mode
set_mode("classification") %>%
set_engine("kknn")
knn_cls_spec
knn_cls_fit <- knn_cls_spec %>% fit(Class ~ ., data = data_train)
knn_cls_fit
bind_cols(
predict(knn_cls_fit, data_test),
predict(knn_cls_fit, data_test, type = "prob")
)
? tidymodels_prefer
View(Chicago)
# modelo prediccion
# cargamos la data
data(Chicago)
View(Chicago)
? Chicago
# seleccionamos variables relevantes
Chicago <- Chicago %>% select(ridership, Clark_Lake, Quincy_Wells)
Chicago_train <- Chicago[1:(n - 7), ]
n
1:(n - 7)
(n - 6):n
# cargo la data
data(two_class_dat)
? two_class_dat
View(two_class_dat)
gc()
pacman::p_load(dbscan, tidyverse, Rtsne, factoextra)
#Aca lee el archivo y lo convierte en un objeto
#Selecionar las columnas que mejor representan la cancion y evitar los datos no nÃºmericos
beats <- readRDS("~/GitHub/Mineria-de-datos/beats.rds") %>%
select("danceability","energy","key","loudness","mode","speechiness","acousticness","instrumentalness","liveness","valence","tempo")%>%
unique()
set.seed(42)
beats_sample<-beats[sample(1:nrow(beats),size=nrow(beats)/10),]
tsne_beats_sample <- Rtsne(beats_sample)%>%
.$Y %>%
as.data.frame()
fviz_nbclust(tsne_beats_sample, kmeans, method = "silhouette")
ggplot(tsne_beats_sample, aes(V1, V2)) + geom_point()
gc?
?gc
?gc
rm(beats_sample,tsne_beats_sample)
tsne_beats <- Rtsne(beats)%>%
.$Y %>%
as.data.frame()
ggplot(tsne_beats_sample, aes(V1, V2)) + geom_point()
ggplot(tsne_beats, aes(V1, V2)) + geom_point()
source("~/GitHub/Mineria-de-datos/Proyecto_1.R")
gc()
pacman::p_load(dbscan, tidyverse, Rtsne, factoextra)
#Aca lee el archivo y lo convierte en un objeto
#Selecionar las columnas que mejor representan la cancion y evitar los datos no nÃºmericos
beats <- readRDS("~/GitHub/Mineria-de-datos/beats.rds") %>%
select(danceability,energy,key,loudness,mode,speechiness,acousticness,instrumentalness,liveness,valence,tempo,time_signature,duration_ms)%>%
unique()
set.seed(40)
beats_sample<-beats[sample(1:nrow(beats),size=nrow(beats)/10),]%>%
scale()%>%
as.data.frame()
tsne_beats_sample <- Rtsne(beats_sample,num_threads=0)%>%
.$Y %>%
as.data.frame()
#Graficar los datos
ggplot(tsne_beats_sample, aes(V1, V2)) + geom_point()
#Mostrar como varia la silueta en funcion del nr de clusters
#fviz_nbclust(tsne_beats_sample, kmeans, method = "silhouette")
#Ejecutar el metodo de k-means para el k nr de centroides
cl<-kmeans(tsne_beats_sample,4)
View(cl)
data1 <- rbind(beats_sample, cl$cluster)
View(data1)
cl$cluster
data1 <- rbind(beats_sample, cl$cluster)
View(data1)
clusters<-cl$cluster
data1 <- rbind(beats_sample, t(cl$cluster))
clusters<-t(cl$cluster)
View(clusters)
clusters<-t(cl$cluster)
clusters<-cl$cluster
data1 <- add_row(beats_sample,cl$cluster)
data1 <- cbind(beats_sample, cl$cluster)
View(data1)
rm(clusters)
tsne_beats <- Rtsne(beats,num_threads=0)%>%
.$Y %>%
as.data.frame()
#Graficar los datos
#ggplot(tsne_beats, aes(V1, V2)) + geom_point()
#Mostrar como varia la silueta en funcion del nr de clusters
fviz_nbclust(tsne_beats, kmeans, method = "silhouette")
#Graficar los datos
#ggplot(tsne_beats, aes(V1, V2)) + geom_point()
#No se puede usar el metodo de encontrar los nr de clusters porque son muchos datos y requiere un espacio exagerado de ram
#fviz_nbclust(tsne_beats, kmeans, method = "silhouette")
#Ejecutar el metodo de k-means para el k nr de centroides
cl<-kmeans(tsne_beats,4)
plot(tsne_beats_sample, col = cl$cluster)
points(cl$centers, col = 1:4, pch = 8)
#Graficar los datos
#ggplot(tsne_beats, aes(V1, V2)) + geom_point()
#No se puede usar el metodo de encontrar los nr de clusters porque son muchos datos y requiere un espacio exagerado de ram
#fviz_nbclust(tsne_beats, kmeans, method = "silhouette")
#Ejecutar el metodo de k-means para el k nr de centroides
cl<-kmeans(tsne_beats,4)
#Graficar los datos
#ggplot(tsne_beats, aes(V1, V2)) + geom_point()
#No se puede usar el metodo de encontrar los nr de clusters porque son muchos datos y requiere un espacio exagerado de ram
#fviz_nbclust(tsne_beats, kmeans, method = "silhouette")
#Ejecutar el metodo de k-means para el k nr de centroides
cl<-kmeans(tsne_beats,4)
View(cl)
plot(tsne_beats, col = cl$cluster)
points(cl$centers, col = 1:4, pch = 8)
###
plot(tsne_beats, col = cl$cluster)
points(cl$centers, col = 1:4, pch = 8)
data_with_cluster <- cbind(readRDS("~/GitHub/Mineria-de-datos/beats.rds") %>%
unique()
, cl$cluster)
beats <- readRDS("~/GitHub/Mineria-de-datos/beats.rds") %>%
unique()
data1 <- cbind(beats
, cl$cluster)
load("~/GitHub/Mineria-de-datos/.RData")
beats <- readRDS("~/GitHub/Mineria-de-datos/beats.rds")
gc()
beats <- readRDS("~/GitHub/Mineria-de-datos/beats.rds")
beats <- readRDS("~/GitHub/Mineria-de-datos/beats.rds") %>%
select(danceability,energy,key,loudness,mode,speechiness,acousticness,instrumentalness,liveness,valence,tempo,time_signature,duration_ms)%>%
unique()
beats <- readRDS("~/GitHub/Mineria-de-datos/beats.rds") %>%
unique()
?Rtsne
beats <- readRDS("~/GitHub/Mineria-de-datos/beats.rds") %>%
select(danceability,energy,key,loudness,mode,speechiness,acousticness,instrumentalness,liveness,valence,tempo,time_signature,duration_ms)
beats <- readRDS("~/GitHub/Mineria-de-datos/beats.rds")
beats <- readRDS("~/GitHub/Mineria-de-datos/beats.rds") %>%
select(danceability,energy,key,loudness,mode,speechiness,acousticness,instrumentalness,liveness,valence,tempo,time_signature,duration_ms)
set.seed(40)
beats_sample<-beats[sample(1:nrow(beats),size=nrow(beats)/10),]%>%
scale()%>%
as.data.frame()
tsne_beats_sample <- Rtsne(beats_sample,num_threads=0,check_duplicates=F)%>%
.$Y %>%
as.data.frame()
#Mostrar como varia la silueta en funcion del nr de clusters
fviz_nbclust(tsne_beats_sample, kmeans, method = "silhouette")
beats_sample<-beats[sample(1:nrow(beats),size=nrow(beats)/12),]%>%
scale()%>%
as.data.frame()
tsne_beats_sample <- Rtsne(beats_sample,num_threads=0,check_duplicates=F)%>%
.$Y %>%
as.data.frame()
#Mostrar como varia la silueta en funcion del nr de clusters
fviz_nbclust(tsne_beats_sample, kmeans, method = "silhouette")
beats <- readRDS("~/GitHub/Mineria-de-datos/beats.rds")
tsne_beats <- Rtsne(beats,num_threads=0)%>%
.$Y %>%
as.data.frame()
tsne_beats <- Rtsne(beats,num_threads=0)%>%
.$Y %>%
as.data.frame()
beats <- readRDS("~/GitHub/Mineria-de-datos/beats.rds")%>%
select(danceability,energy,key,loudness,mode,speechiness,acousticness,instrumentalness,liveness,valence,tempo,time_signature,duration_ms)
tsne_beats <- Rtsne(beats,num_threads=0)%>%
.$Y %>%
as.data.frame()
tsne_beats <- Rtsne(beats,num_threads=0,check_duplicates=F)%>%
.$Y %>%
as.data.frame()
#Ejecutar el metodo de k-means para el k nr de centroides
cl<-kmeans(tsne_beats,4)
plot(tsne_beats, col = cl$cluster)
points(cl$centers, col = 1:4, pch = 8)
